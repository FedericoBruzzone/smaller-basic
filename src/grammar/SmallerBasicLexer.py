# Generated from src/grammar/SmallerBasic.g4 by ANTLR 4.12.0
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
    from typing import TextIO
else:
    from typing.io import TextIO


def serializedATN():
    return [
        4,0,14,139,6,-1,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,
        2,6,7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,
        13,7,13,1,0,1,0,1,0,1,0,1,1,1,1,1,2,1,2,1,2,3,2,39,8,2,1,3,3,3,42,
        8,3,1,3,1,3,5,3,46,8,3,10,3,12,3,49,9,3,1,3,3,3,52,8,3,1,3,1,3,4,
        3,56,8,3,11,3,12,3,57,1,3,3,3,61,8,3,1,4,3,4,64,8,4,1,4,1,4,5,4,
        68,8,4,10,4,12,4,71,9,4,1,4,3,4,74,8,4,1,5,1,5,3,5,78,8,5,1,5,4,
        5,81,8,5,11,5,12,5,82,1,6,1,6,1,7,1,7,1,8,1,8,1,8,5,8,92,8,8,10,
        8,12,8,95,9,8,1,9,1,9,5,9,99,8,9,10,9,12,9,102,9,9,1,9,1,9,1,10,
        1,10,1,11,4,11,109,8,11,11,11,12,11,110,1,11,1,11,1,12,1,12,1,12,
        1,12,5,12,119,8,12,10,12,12,12,122,9,12,1,12,1,12,1,12,1,12,1,12,
        1,13,1,13,1,13,1,13,5,13,133,8,13,10,13,12,13,136,9,13,1,13,1,13,
        1,120,0,14,1,1,3,2,5,3,7,4,9,5,11,6,13,7,15,8,17,9,19,10,21,11,23,
        12,25,13,27,14,1,0,8,1,0,49,57,2,0,69,69,101,101,1,0,48,57,2,0,43,
        43,45,45,3,0,0,31,34,34,127,127,2,0,65,90,97,122,3,0,9,10,13,13,
        32,32,2,0,10,10,13,13,157,0,1,1,0,0,0,0,3,1,0,0,0,0,5,1,0,0,0,0,
        7,1,0,0,0,0,9,1,0,0,0,0,11,1,0,0,0,0,13,1,0,0,0,0,15,1,0,0,0,0,17,
        1,0,0,0,0,19,1,0,0,0,0,21,1,0,0,0,0,23,1,0,0,0,0,25,1,0,0,0,0,27,
        1,0,0,0,1,29,1,0,0,0,3,33,1,0,0,0,5,38,1,0,0,0,7,41,1,0,0,0,9,63,
        1,0,0,0,11,75,1,0,0,0,13,84,1,0,0,0,15,86,1,0,0,0,17,88,1,0,0,0,
        19,96,1,0,0,0,21,105,1,0,0,0,23,108,1,0,0,0,25,114,1,0,0,0,27,128,
        1,0,0,0,29,30,5,118,0,0,30,31,5,97,0,0,31,32,5,114,0,0,32,2,1,0,
        0,0,33,34,5,61,0,0,34,4,1,0,0,0,35,39,3,9,4,0,36,39,3,7,3,0,37,39,
        5,48,0,0,38,35,1,0,0,0,38,36,1,0,0,0,38,37,1,0,0,0,39,6,1,0,0,0,
        40,42,3,15,7,0,41,40,1,0,0,0,41,42,1,0,0,0,42,51,1,0,0,0,43,47,7,
        0,0,0,44,46,3,13,6,0,45,44,1,0,0,0,46,49,1,0,0,0,47,45,1,0,0,0,47,
        48,1,0,0,0,48,52,1,0,0,0,49,47,1,0,0,0,50,52,5,48,0,0,51,43,1,0,
        0,0,51,50,1,0,0,0,51,52,1,0,0,0,52,53,1,0,0,0,53,55,5,46,0,0,54,
        56,3,13,6,0,55,54,1,0,0,0,56,57,1,0,0,0,57,55,1,0,0,0,57,58,1,0,
        0,0,58,60,1,0,0,0,59,61,3,11,5,0,60,59,1,0,0,0,60,61,1,0,0,0,61,
        8,1,0,0,0,62,64,3,15,7,0,63,62,1,0,0,0,63,64,1,0,0,0,64,65,1,0,0,
        0,65,69,7,0,0,0,66,68,3,13,6,0,67,66,1,0,0,0,68,71,1,0,0,0,69,67,
        1,0,0,0,69,70,1,0,0,0,70,73,1,0,0,0,71,69,1,0,0,0,72,74,3,11,5,0,
        73,72,1,0,0,0,73,74,1,0,0,0,74,10,1,0,0,0,75,77,7,1,0,0,76,78,3,
        15,7,0,77,76,1,0,0,0,77,78,1,0,0,0,78,80,1,0,0,0,79,81,3,13,6,0,
        80,79,1,0,0,0,81,82,1,0,0,0,82,80,1,0,0,0,82,83,1,0,0,0,83,12,1,
        0,0,0,84,85,7,2,0,0,85,14,1,0,0,0,86,87,7,3,0,0,87,16,1,0,0,0,88,
        93,3,21,10,0,89,92,3,21,10,0,90,92,3,13,6,0,91,89,1,0,0,0,91,90,
        1,0,0,0,92,95,1,0,0,0,93,91,1,0,0,0,93,94,1,0,0,0,94,18,1,0,0,0,
        95,93,1,0,0,0,96,100,5,34,0,0,97,99,8,4,0,0,98,97,1,0,0,0,99,102,
        1,0,0,0,100,98,1,0,0,0,100,101,1,0,0,0,101,103,1,0,0,0,102,100,1,
        0,0,0,103,104,5,34,0,0,104,20,1,0,0,0,105,106,7,5,0,0,106,22,1,0,
        0,0,107,109,7,6,0,0,108,107,1,0,0,0,109,110,1,0,0,0,110,108,1,0,
        0,0,110,111,1,0,0,0,111,112,1,0,0,0,112,113,6,11,0,0,113,24,1,0,
        0,0,114,115,5,47,0,0,115,116,5,42,0,0,116,120,1,0,0,0,117,119,9,
        0,0,0,118,117,1,0,0,0,119,122,1,0,0,0,120,121,1,0,0,0,120,118,1,
        0,0,0,121,123,1,0,0,0,122,120,1,0,0,0,123,124,5,42,0,0,124,125,5,
        47,0,0,125,126,1,0,0,0,126,127,6,12,0,0,127,26,1,0,0,0,128,129,5,
        47,0,0,129,130,5,47,0,0,130,134,1,0,0,0,131,133,8,7,0,0,132,131,
        1,0,0,0,133,136,1,0,0,0,134,132,1,0,0,0,134,135,1,0,0,0,135,137,
        1,0,0,0,136,134,1,0,0,0,137,138,6,13,0,0,138,28,1,0,0,0,18,0,38,
        41,47,51,57,60,63,69,73,77,82,91,93,100,110,120,134,1,6,0,0
    ]

class SmallerBasicLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    T__0 = 1
    T__1 = 2
    NUM = 3
    FLOAT = 4
    INT = 5
    EXPONENT = 6
    NUMBER = 7
    SIGN = 8
    ID = 9
    STRINGLITERAL = 10
    LETTER = 11
    WS = 12
    COMMENT = 13
    LINE_COMMENT = 14

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "'var'", "'='" ]

    symbolicNames = [ "<INVALID>",
            "NUM", "FLOAT", "INT", "EXPONENT", "NUMBER", "SIGN", "ID", "STRINGLITERAL", 
            "LETTER", "WS", "COMMENT", "LINE_COMMENT" ]

    ruleNames = [ "T__0", "T__1", "NUM", "FLOAT", "INT", "EXPONENT", "NUMBER", 
                  "SIGN", "ID", "STRINGLITERAL", "LETTER", "WS", "COMMENT", 
                  "LINE_COMMENT" ]

    grammarFileName = "SmallerBasic.g4"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.12.0")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


